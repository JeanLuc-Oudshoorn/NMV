{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMOIqfhcyBCC1FiHaR65y8C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeanLuc-Oudshoorn/Net_Merchandise_Value/blob/master/nmv_model_in_pyspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building a machine learning model to forecast net merchandise value"
      ],
      "metadata": {
        "id": "Cy16b6abBj90"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we will be building an adaptive model to forecast NMV. In order to do so, we have to explode the data which will result in a very large input dataframe. Therefore the PySpark API will be used to train the model."
      ],
      "metadata": {
        "id": "cql-cZdoBmjH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing PySpark on Colab"
      ],
      "metadata": {
        "id": "u7K8UXmWBqGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A few commands are needed to install and activate PySpark on Colab. This should only take about a minute."
      ],
      "metadata": {
        "id": "iTnwbr1fBtEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.4.0/spark-3.4.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.4.0-bin-hadoop3.tgz\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "6io7FSDvBw8b"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.0-bin-hadoop3\""
      ],
      "metadata": {
        "id": "tCcAcswUBynu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "MheLa6CZB0Yk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If PySpark is successfully loaded in the environment we can now create a spark session. We can give it a name and add external repositories and packages with the 'config' option. The command below loads the PySpark implementation for the LightGBM algorithm."
      ],
      "metadata": {
        "id": "NnuZGIewB30r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "spark = pyspark.sql.SparkSession.builder.appName(\"NMV Model\")\\\n",
        "                                        .config(\"spark.jars.packages\", \"com.microsoft.azure:synapseml_2.12:0.11.0\")\\\n",
        "                                        .config(\"spark.jars.repositories\", \"https://mmlspark.azureedge.net/maven\")\\\n",
        "                                        .getOrCreate()"
      ],
      "metadata": {
        "id": "l7E-RwTzB5Mp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now check if the spark session is build correctly. In this case it will only be a local session, so we could also have used pandas. In reality, the application would be run on a Hadoop cluster."
      ],
      "metadata": {
        "id": "a0ArEbkIB9X_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "CaOoXqBOB7OV",
        "outputId": "cf8ef15f-cf2e-47d5-b0b4-99754ac9d450"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fa610b5d8d0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://bffaaa9daef5:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>NMV Model</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the simulated data"
      ],
      "metadata": {
        "id": "-CJ_XHkACFMn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this example we will be using a *simulated* data set, specifically developed for this training. Because the data is fake, it might contain some quirks that you would not see in real data (e.g.: strange color & product group combinations). We can read the file directly from the GitHub link and add it to the spark session."
      ],
      "metadata": {
        "id": "VmPct8j8CIoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkFiles\n",
        "url = 'https://raw.githubusercontent.com/JeanLuc-Oudshoorn/Net_Merchandise_Value/master/fashion_data_simulation.csv'\n",
        "\n",
        "spark.sparkContext.addFile(url)\n",
        "\n",
        "df = spark.read.csv(\"file://\"+SparkFiles.get(\"fashion_data_simulation.csv\"), header=True, inferSchema= True)"
      ],
      "metadata": {
        "id": "OFD1xxg5CTvj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data looks as follows. In a real NMV project it will most likely be required to load historical orders and product information as two separate tables and join them togheter. For sake of simplicity, this step is skipped here."
      ],
      "metadata": {
        "id": "axKZHe_2Htad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_U7TzTnCYby",
        "outputId": "0ab19fff-23f6-4ec7-be2f-9e63cd49d325"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------+--------+-----------+-------------+-------------+----+---------------+------------+-------+-----+-----------+----------+-----------+-------------+\n",
            "| color|        brand|order_id|customer_id|product_group|product_class|size|sold_to_country|prod_country|    fit|price|is_returned|order_date|return_date|item_trans_id|\n",
            "+------+-------------+--------+-----------+-------------+-------------+----+---------------+------------+-------+-----+-----------+----------+-----------+-------------+\n",
            "|  Blue|         Zara|     101|       7884|         Polo|       Casual|   L|          Spain|  Bangladesh|Regular|  180|          1|2021-08-01| 2021-08-12|            0|\n",
            "| Black|         Zara|     101|       7884|       Loafer|         null|   S|        Denmark|    Portugal|   Slim|  174|          1|2021-08-01| 2021-08-10|            1|\n",
            "| White|         Zara|     431|      59945|      Handbag|  Accessories|null|          Spain|      Turkey|   null|  227|          0|2021-08-01|       null|            2|\n",
            "|   Red|         Zara|     688|      29730|      Overall|        Denim|   S|        Denmark|    Portugal|   Slim|  239|          0|2021-08-01|       null|            3|\n",
            "| Multi|Massimo Dutti|     688|      29730|        Dress|    Non-denim|   L|         France|     Vietnam|Regular|  244|          1|2021-08-01| 2021-08-19|            4|\n",
            "| Multi|         Zara|    1170|       8495|          Tee|    Non-denim|   M|        Austria|     Vietnam|Regular|  251|          0|2021-08-01|       null|            5|\n",
            "|  Blue|         Zara|    1170|       8495|        Dress|    Non-denim|   L|        Denmark|     Vietnam|Regular|  181|          0|2021-08-01|       null|            6|\n",
            "| Multi|         Zara|    1500|      24091|        Chino|    Non-denim|   L|          Spain|      Turkey|   Slim|  178|          1|2021-08-01| 2021-08-06|            7|\n",
            "| Brown|         Zara|    2727|      47757|          Tee|    Non-denim|   L|         France|    Portugal|Regular|  134|          0|2021-08-01|       null|            8|\n",
            "|  Blue|Massimo Dutti|    2868|       1734|        Scarf|  Accessories|null|         France|    Portugal|   null|  306|          0|2021-08-01| 2021-08-11|            9|\n",
            "| Black|         Zara|    2868|       1734|         Polo|       Casual|   S|        Estonia|  Bangladesh|Comfort|  197|          0|2021-08-01|       null|           10|\n",
            "|  Blue|         Zara|    2868|       1734|        Chino|    Non-denim|   L|        Finland|  Bangladesh| Skinny|  230|          0|2021-08-01|       null|           11|\n",
            "|   Red|         Zara|    2887|      38339|        Scarf|  Accessories|null|          Italy|      Turkey|   null|  256|          0|2021-08-01|       null|           12|\n",
            "| Multi|         Zara|    2887|      38339|        Shirt|       Casual|   M|          Spain|       China| Skinny|  150|          1|2021-08-01| 2021-08-12|           13|\n",
            "|Orange|         Zara|    3282|      54930|        Jeans|        Denim|   S|  Great Britain|  Bangladesh|Comfort|  331|          0|2021-08-01|       null|           14|\n",
            "|  null|         Zara|    3282|      54930|         Belt|  Accessories|null|  Great Britain|     Vietnam|   null|  267|          1|2021-08-01| 2021-08-12|           15|\n",
            "|Orange|         Zara|    3282|      54930|         Polo|       Casual|   L|          Spain|    Portugal|   Slim|  277|          0|2021-08-01|       null|           16|\n",
            "|  Blue|         Zara|    3282|      54930|      Overall|        Denim|   S|        Austria|    Portugal| Skinny|  179|          1|2021-08-01| 2021-08-17|           17|\n",
            "|  Blue|         Zara|    3282|      54930|        Scarf|  Accessories|null|         Sweden|     Vietnam|   null|  255|          0|2021-08-01|       null|           18|\n",
            "| White|  Pull & Bear|    3483|      59887|        Chino|    Non-denim|   M|  Great Britain|      Turkey|Regular|  242|          0|2021-08-01|       null|           19|\n",
            "+------+-------------+--------+-----------+-------------+-------------+----+---------------+------------+-------+-----+-----------+----------+-----------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Engineering"
      ],
      "metadata": {
        "id": "hzyqvSHGIeZx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Date Features\n",
        "Clearly, there are some opportunities for feature engineering in this data. For example, the order date cannot be used in its current form. Instead we can derive new predictive features from the order date."
      ],
      "metadata": {
        "id": "FfXDJECvIhf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Order day of year\n",
        "df = df.withColumn('day_of_year', F.dayofyear(F.col('order_date')))\n",
        "\n",
        "# Order year\n",
        "df = df.withColumn('year', F.year(F.col('order_date')))\n",
        "\n",
        "# Order month\n",
        "df = df.withColumn('month', F.month(F.col('order_date')))\n",
        "\n",
        "# Order week of year\n",
        "df = df.withColumn('week_of_year', F.weekofyear(F.col('order_date')))"
      ],
      "metadata": {
        "id": "o2k2JGhCExuc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now check to see if the new features were created properly."
      ],
      "metadata": {
        "id": "t25L82FnJpa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NiCz123JZ6o",
        "outputId": "0306ffca-4453-4618-8c12-67293ebdbace"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------+--------+-----------+-------------+-------------+----+---------------+------------+-------+-----+-----------+----------+-----------+-------------+-----------+----+-----+------------+\n",
            "| color|        brand|order_id|customer_id|product_group|product_class|size|sold_to_country|prod_country|    fit|price|is_returned|order_date|return_date|item_trans_id|day_of_year|year|month|week_of_year|\n",
            "+------+-------------+--------+-----------+-------------+-------------+----+---------------+------------+-------+-----+-----------+----------+-----------+-------------+-----------+----+-----+------------+\n",
            "|  Blue|         Zara|     101|       7884|         Polo|       Casual|   L|          Spain|  Bangladesh|Regular|  180|          1|2021-08-01| 2021-08-12|            0|        213|2021|    8|          30|\n",
            "| Black|         Zara|     101|       7884|       Loafer|         null|   S|        Denmark|    Portugal|   Slim|  174|          1|2021-08-01| 2021-08-10|            1|        213|2021|    8|          30|\n",
            "| White|         Zara|     431|      59945|      Handbag|  Accessories|null|          Spain|      Turkey|   null|  227|          0|2021-08-01|       null|            2|        213|2021|    8|          30|\n",
            "|   Red|         Zara|     688|      29730|      Overall|        Denim|   S|        Denmark|    Portugal|   Slim|  239|          0|2021-08-01|       null|            3|        213|2021|    8|          30|\n",
            "| Multi|Massimo Dutti|     688|      29730|        Dress|    Non-denim|   L|         France|     Vietnam|Regular|  244|          1|2021-08-01| 2021-08-19|            4|        213|2021|    8|          30|\n",
            "| Multi|         Zara|    1170|       8495|          Tee|    Non-denim|   M|        Austria|     Vietnam|Regular|  251|          0|2021-08-01|       null|            5|        213|2021|    8|          30|\n",
            "|  Blue|         Zara|    1170|       8495|        Dress|    Non-denim|   L|        Denmark|     Vietnam|Regular|  181|          0|2021-08-01|       null|            6|        213|2021|    8|          30|\n",
            "| Multi|         Zara|    1500|      24091|        Chino|    Non-denim|   L|          Spain|      Turkey|   Slim|  178|          1|2021-08-01| 2021-08-06|            7|        213|2021|    8|          30|\n",
            "| Brown|         Zara|    2727|      47757|          Tee|    Non-denim|   L|         France|    Portugal|Regular|  134|          0|2021-08-01|       null|            8|        213|2021|    8|          30|\n",
            "|  Blue|Massimo Dutti|    2868|       1734|        Scarf|  Accessories|null|         France|    Portugal|   null|  306|          0|2021-08-01| 2021-08-11|            9|        213|2021|    8|          30|\n",
            "| Black|         Zara|    2868|       1734|         Polo|       Casual|   S|        Estonia|  Bangladesh|Comfort|  197|          0|2021-08-01|       null|           10|        213|2021|    8|          30|\n",
            "|  Blue|         Zara|    2868|       1734|        Chino|    Non-denim|   L|        Finland|  Bangladesh| Skinny|  230|          0|2021-08-01|       null|           11|        213|2021|    8|          30|\n",
            "|   Red|         Zara|    2887|      38339|        Scarf|  Accessories|null|          Italy|      Turkey|   null|  256|          0|2021-08-01|       null|           12|        213|2021|    8|          30|\n",
            "| Multi|         Zara|    2887|      38339|        Shirt|       Casual|   M|          Spain|       China| Skinny|  150|          1|2021-08-01| 2021-08-12|           13|        213|2021|    8|          30|\n",
            "|Orange|         Zara|    3282|      54930|        Jeans|        Denim|   S|  Great Britain|  Bangladesh|Comfort|  331|          0|2021-08-01|       null|           14|        213|2021|    8|          30|\n",
            "|  null|         Zara|    3282|      54930|         Belt|  Accessories|null|  Great Britain|     Vietnam|   null|  267|          1|2021-08-01| 2021-08-12|           15|        213|2021|    8|          30|\n",
            "|Orange|         Zara|    3282|      54930|         Polo|       Casual|   L|          Spain|    Portugal|   Slim|  277|          0|2021-08-01|       null|           16|        213|2021|    8|          30|\n",
            "|  Blue|         Zara|    3282|      54930|      Overall|        Denim|   S|        Austria|    Portugal| Skinny|  179|          1|2021-08-01| 2021-08-17|           17|        213|2021|    8|          30|\n",
            "|  Blue|         Zara|    3282|      54930|        Scarf|  Accessories|null|         Sweden|     Vietnam|   null|  255|          0|2021-08-01|       null|           18|        213|2021|    8|          30|\n",
            "| White|  Pull & Bear|    3483|      59887|        Chino|    Non-denim|   M|  Great Britain|      Turkey|Regular|  242|          0|2021-08-01|       null|           19|        213|2021|    8|          30|\n",
            "+------+-------------+--------+-----------+-------------+-------------+----+---------------+------------+-------+-----+-----------+----------+-----------+-------------+-----------+----+-----+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Geometric Transformations\n",
        "One-hot encoding the day of year will lead to many new columns in the data. Below is an example of how to geometrically transform this feature."
      ],
      "metadata": {
        "id": "9-7Wqun1J3Mv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sine base function\n",
        "def sin_base(x, period=365.25):\n",
        "    return float(np.sin(x / period * 2 * np.pi))\n",
        "\n",
        "# Cosine base function\n",
        "def cos_base(x, period=365.25):\n",
        "    return float(np.cos(x / period * 2 * np.pi))\n",
        "\n",
        "# Convert into PySpark function\n",
        "sin_transformer = F.udf(lambda x:sin_base(x)) \n",
        "\n",
        "# Convert into PySpark function\n",
        "cos_transformer = F.udf(lambda x:cos_base(x)) "
      ],
      "metadata": {
        "id": "lfxYzpvZKCzZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After creating the geometric transformers we only have to apply them to the correct column."
      ],
      "metadata": {
        "id": "0oqQ-sRtKJ8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply transformation\n",
        "df = df.withColumn('sin_order_date', sin_transformer(F.col('day_of_year')))\n",
        "df = df.withColumn('cos_order_date', cos_transformer(F.col('day_of_year')))"
      ],
      "metadata": {
        "id": "ZDCmkm-iKPUy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.select('order_date', 'sin_order_date', 'cos_order_date').distinct().orderBy('order_date').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIacXL31T0zf",
        "outputId": "ce52f230-b478-4d4a-8200-e443b38accf9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+-------------------+\n",
            "|order_date|      sin_order_date|     cos_order_date|\n",
            "+----------+--------------------+-------------------+\n",
            "|2021-08-01|-0.49906860268853154|-0.8665624788845387|\n",
            "|2021-08-02| -0.5139010013093099|-0.8578494977869303|\n",
            "|2021-08-03| -0.5285813283559295|-0.8488826652214551|\n",
            "|2021-08-04|  -0.543105239683432|-0.8396646346181323|\n",
            "|2021-08-05| -0.5574684374327888|-0.8301981337405215|\n",
            "|2021-08-06| -0.5716666713027055|-0.8204859638785325|\n",
            "|2021-08-07| -0.5856957398073508|-0.8105309990194823|\n",
            "|2021-08-08| -0.5995514915196486|-0.8003361849976326|\n",
            "|2021-08-09| -0.6132298262997502|-0.7899045386224707|\n",
            "|2021-08-10| -0.6267266965083301|-0.7792391467859886|\n",
            "|2021-08-11| -0.6400381082043503|-0.7683431655492202|\n",
            "|2021-08-12| -0.6531601223269297| -0.757219819208313|\n",
            "|2021-08-13|  -0.666088855860977|-0.7458723993404063|\n",
            "|2021-08-14| -0.6788204829862355| -0.734304263829602|\n",
            "|2021-08-15| -0.6913512362094071| -0.722518835873311|\n",
            "|2021-08-16| -0.7036774074790131|-0.7105196029692742|\n",
            "|2021-08-17| -0.7157953492826645|-0.6983101158835581|\n",
            "|2021-08-18| -0.7277014757264233|-0.6858939875998227|\n",
            "|2021-08-19| -0.7393922635959241| -0.673274892250183|\n",
            "|2021-08-20| -0.7508642533989489|-0.6604565640279754|\n",
            "+----------+--------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Order Features\n",
        "Order features can be engineered by using a window and selectively partitioning on the desired features. Then we can count or sum over the window to create the feature that we want."
      ],
      "metadata": {
        "id": "-0OhtcyIKVRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import types as T\n",
        "from pyspark.sql import Window as psw\n",
        "\n",
        "# Total number of items in one order\n",
        "w = psw.orderBy('order_date').partitionBy('order_id') \n",
        "df = df.withColumn('n_item_same_order', F.count('item_trans_id').over(w))\n",
        "\n",
        "# Number of items in the same product class in the same order\n",
        "w = psw.orderBy('order_date').partitionBy('order_id', 'product_class')\n",
        "df = df.withColumn('n_same_pc_same_order', F.count('item_trans_id').over(w))\n",
        "df = df.fillna(0, subset=[\"n_same_pc_same_order\"])\n",
        "\n",
        "# Number of items in the same product group in the same order\n",
        "w = psw.orderBy('order_date').partitionBy('order_id', 'product_group')\n",
        "df = df.withColumn('n_same_pg_same_order', F.count('item_trans_id').over(w))\n",
        "df = df.fillna(0, subset=[\"n_same_pg_same_order\"])\n",
        "\n",
        "# Total order value\n",
        "w = psw.orderBy('order_date').partitionBy('order_id')\n",
        "df = df.withColumn('order_value', F.sum('price').over(w))\n",
        "df = df.fillna(0, subset=[\"order_value\"])"
      ],
      "metadata": {
        "id": "B74GHOjWKmKN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Explosion\n",
        "To make adaptive forecasts, the data needs to be exploded. One key assumption here is that customers will return all unwanted items at once. That is to say, if one of multiple items in an order is returned, we assume the rest is kept. We will also keep an unexploded version of the data because we will need this later for statistical features."
      ],
      "metadata": {
        "id": "c_IPDbqZLl1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep an unexploded version\n",
        "df_order_unexpl = df.alias('df_unexpl')"
      ],
      "metadata": {
        "id": "LmtOcJQYNceE"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime as dt\n",
        "\n",
        "# Transform\n",
        "def explode_data(df_order,\n",
        "                 return_window_size=33,\n",
        "                ):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "\n",
        "    # Create the purchase_order_return_date for all orders\n",
        "    # Because if an item in a purchase order has been returned,\n",
        "    # we will stop predicting for all items in this order\n",
        "\n",
        "    w = psw.orderBy('order_date').partitionBy('order_id')\n",
        "    df_order = (df_order\n",
        "                .withColumn(\"is_purchase_order_returned\", F.max('is_returned').over(w))\n",
        "                .withColumn(\"purchase_order_return_date\", F.min('return_date').over(w))\n",
        "                .withColumn('purchase_order_return_date', F.when(F.col('purchase_order_return_date').isNull(),\n",
        "                                                                 F.to_date(F.lit('2099-01-01'), 'yyyy-MM-dd'))\n",
        "                            .otherwise(F.col('purchase_order_return_date')))\n",
        "                )\n",
        "\n",
        "    # Explode the data by the size of return window\n",
        "    # Remove all the items in an order if one of the item has been returned\n",
        "\n",
        "    df_order_expl = (\n",
        "        df_order.withColumn('arr_days_after_order', F.array([F.lit(x) for x in range(return_window_size + 1)]))\n",
        "            .withColumn(\"days_after_order\", F.explode(\"arr_days_after_order\"))\n",
        "            .withColumn(\"current_date\",\n",
        "                        F.udf(lambda x, y: x + dt.timedelta(days=y), T.DateType())(F.col(\"order_date\"),\n",
        "                                                                                   F.col(\n",
        "                                                                                       \"days_after_order\")))\n",
        "            .filter(F.col(\"current_date\") < F.col(\"purchase_order_return_date\"))\n",
        "    )\n",
        "\n",
        "    return df_order_expl"
      ],
      "metadata": {
        "id": "2N8Dp4mIL8s6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even though the return window is only 30 days, we assume a 33 day return window to account for shipping time."
      ],
      "metadata": {
        "id": "DmhOcsckNmtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = explode_data(df, return_window_size = 33)"
      ],
      "metadata": {
        "id": "WwgFP21yNf6c"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result of the explosion is a data frame with many rows per item, with different values for 'days_after_order' and 'current_date'."
      ],
      "metadata": {
        "id": "Hpv7vKS3VPjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSes_uwoVL8o",
        "outputId": "c7da5ca3-de21-4e6c-9ea3-4e8ef5194412"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+--------+-----------+-------------+-------------+----+---------------+------------+-------+-----+-----------+----------+-----------+-------------+-----------+----+-----+------------+-------------------+--------------------+-----------------+----------------------------+--------------------+--------------------+-----------+--------------------------+--------------------------+--------------------+----------------+------------+\n",
            "|color|brand|order_id|customer_id|product_group|product_class|size|sold_to_country|prod_country|    fit|price|is_returned|order_date|return_date|item_trans_id|day_of_year|year|month|week_of_year|     sin_order_date|      cos_order_date|n_item_same_order|n_prod_same_ptype_same_order|n_same_pc_same_order|n_same_pg_same_order|order_value|is_purchase_order_returned|purchase_order_return_date|arr_days_after_order|days_after_order|current_date|\n",
            "+-----+-----+--------+-----------+-------------+-------------+----+---------------+------------+-------+-----+-----------+----------+-----------+-------------+-----------+----+-----+------------+-------------------+--------------------+-----------------+----------------------------+--------------------+--------------------+-----------+--------------------------+--------------------------+--------------------+----------------+------------+\n",
            "|  Red| Zara|       5|      58197|        Scarf|  Accessories|null|  Great Britain|    Portugal|   null|  291|          1|2022-04-21| 2022-05-02|        60026|        111|2022|    4|          16| 0.9431964659565866|-0.33223549871590435|                1|                           1|                   1|                   1|        291|                         1|                2022-05-02|[0, 1, 2, 3, 4, 5...|               0|  2022-04-21|\n",
            "|  Red| Zara|       5|      58197|        Scarf|  Accessories|null|  Great Britain|    Portugal|   null|  291|          1|2022-04-21| 2022-05-02|        60026|        111|2022|    4|          16| 0.9431964659565866|-0.33223549871590435|                1|                           1|                   1|                   1|        291|                         1|                2022-05-02|[0, 1, 2, 3, 4, 5...|               1|  2022-04-22|\n",
            "|  Red| Zara|       5|      58197|        Scarf|  Accessories|null|  Great Britain|    Portugal|   null|  291|          1|2022-04-21| 2022-05-02|        60026|        111|2022|    4|          16| 0.9431964659565866|-0.33223549871590435|                1|                           1|                   1|                   1|        291|                         1|                2022-05-02|[0, 1, 2, 3, 4, 5...|               2|  2022-04-23|\n",
            "|  Red| Zara|       5|      58197|        Scarf|  Accessories|null|  Great Britain|    Portugal|   null|  291|          1|2022-04-21| 2022-05-02|        60026|        111|2022|    4|          16| 0.9431964659565866|-0.33223549871590435|                1|                           1|                   1|                   1|        291|                         1|                2022-05-02|[0, 1, 2, 3, 4, 5...|               3|  2022-04-24|\n",
            "|  Red| Zara|       5|      58197|        Scarf|  Accessories|null|  Great Britain|    Portugal|   null|  291|          1|2022-04-21| 2022-05-02|        60026|        111|2022|    4|          16| 0.9431964659565866|-0.33223549871590435|                1|                           1|                   1|                   1|        291|                         1|                2022-05-02|[0, 1, 2, 3, 4, 5...|               4|  2022-04-25|\n",
            "|  Red| Zara|       5|      58197|        Scarf|  Accessories|null|  Great Britain|    Portugal|   null|  291|          1|2022-04-21| 2022-05-02|        60026|        111|2022|    4|          16| 0.9431964659565866|-0.33223549871590435|                1|                           1|                   1|                   1|        291|                         1|                2022-05-02|[0, 1, 2, 3, 4, 5...|               5|  2022-04-26|\n",
            "|  Red| Zara|       5|      58197|        Scarf|  Accessories|null|  Great Britain|    Portugal|   null|  291|          1|2022-04-21| 2022-05-02|        60026|        111|2022|    4|          16| 0.9431964659565866|-0.33223549871590435|                1|                           1|                   1|                   1|        291|                         1|                2022-05-02|[0, 1, 2, 3, 4, 5...|               6|  2022-04-27|\n",
            "|  Red| Zara|       5|      58197|        Scarf|  Accessories|null|  Great Britain|    Portugal|   null|  291|          1|2022-04-21| 2022-05-02|        60026|        111|2022|    4|          16| 0.9431964659565866|-0.33223549871590435|                1|                           1|                   1|                   1|        291|                         1|                2022-05-02|[0, 1, 2, 3, 4, 5...|               7|  2022-04-28|\n",
            "|  Red| Zara|       5|      58197|        Scarf|  Accessories|null|  Great Britain|    Portugal|   null|  291|          1|2022-04-21| 2022-05-02|        60026|        111|2022|    4|          16| 0.9431964659565866|-0.33223549871590435|                1|                           1|                   1|                   1|        291|                         1|                2022-05-02|[0, 1, 2, 3, 4, 5...|               8|  2022-04-29|\n",
            "|  Red| Zara|       5|      58197|        Scarf|  Accessories|null|  Great Britain|    Portugal|   null|  291|          1|2022-04-21| 2022-05-02|        60026|        111|2022|    4|          16| 0.9431964659565866|-0.33223549871590435|                1|                           1|                   1|                   1|        291|                         1|                2022-05-02|[0, 1, 2, 3, 4, 5...|               9|  2022-04-30|\n",
            "|  Red| Zara|       5|      58197|        Scarf|  Accessories|null|  Great Britain|    Portugal|   null|  291|          1|2022-04-21| 2022-05-02|        60026|        111|2022|    4|          16| 0.9431964659565866|-0.33223549871590435|                1|                           1|                   1|                   1|        291|                         1|                2022-05-02|[0, 1, 2, 3, 4, 5...|              10|  2022-05-01|\n",
            "|White| Zara|       6|      23757|        Chino|    Non-denim|   S|        Germany|     Vietnam|Comfort|   95|          0|2022-07-19|       null|       105254|        200|2022|    7|          29|-0.2944616217868008| -0.9556633054034706|                1|                           1|                   1|                   1|         95|                         0|                2099-01-01|[0, 1, 2, 3, 4, 5...|               0|  2022-07-19|\n",
            "|White| Zara|       6|      23757|        Chino|    Non-denim|   S|        Germany|     Vietnam|Comfort|   95|          0|2022-07-19|       null|       105254|        200|2022|    7|          29|-0.2944616217868008| -0.9556633054034706|                1|                           1|                   1|                   1|         95|                         0|                2099-01-01|[0, 1, 2, 3, 4, 5...|               1|  2022-07-20|\n",
            "|White| Zara|       6|      23757|        Chino|    Non-denim|   S|        Germany|     Vietnam|Comfort|   95|          0|2022-07-19|       null|       105254|        200|2022|    7|          29|-0.2944616217868008| -0.9556633054034706|                1|                           1|                   1|                   1|         95|                         0|                2099-01-01|[0, 1, 2, 3, 4, 5...|               2|  2022-07-21|\n",
            "|White| Zara|       6|      23757|        Chino|    Non-denim|   S|        Germany|     Vietnam|Comfort|   95|          0|2022-07-19|       null|       105254|        200|2022|    7|          29|-0.2944616217868008| -0.9556633054034706|                1|                           1|                   1|                   1|         95|                         0|                2099-01-01|[0, 1, 2, 3, 4, 5...|               3|  2022-07-22|\n",
            "|White| Zara|       6|      23757|        Chino|    Non-denim|   S|        Germany|     Vietnam|Comfort|   95|          0|2022-07-19|       null|       105254|        200|2022|    7|          29|-0.2944616217868008| -0.9556633054034706|                1|                           1|                   1|                   1|         95|                         0|                2099-01-01|[0, 1, 2, 3, 4, 5...|               4|  2022-07-23|\n",
            "|White| Zara|       6|      23757|        Chino|    Non-denim|   S|        Germany|     Vietnam|Comfort|   95|          0|2022-07-19|       null|       105254|        200|2022|    7|          29|-0.2944616217868008| -0.9556633054034706|                1|                           1|                   1|                   1|         95|                         0|                2099-01-01|[0, 1, 2, 3, 4, 5...|               5|  2022-07-24|\n",
            "|White| Zara|       6|      23757|        Chino|    Non-denim|   S|        Germany|     Vietnam|Comfort|   95|          0|2022-07-19|       null|       105254|        200|2022|    7|          29|-0.2944616217868008| -0.9556633054034706|                1|                           1|                   1|                   1|         95|                         0|                2099-01-01|[0, 1, 2, 3, 4, 5...|               6|  2022-07-25|\n",
            "|White| Zara|       6|      23757|        Chino|    Non-denim|   S|        Germany|     Vietnam|Comfort|   95|          0|2022-07-19|       null|       105254|        200|2022|    7|          29|-0.2944616217868008| -0.9556633054034706|                1|                           1|                   1|                   1|         95|                         0|                2099-01-01|[0, 1, 2, 3, 4, 5...|               7|  2022-07-26|\n",
            "|White| Zara|       6|      23757|        Chino|    Non-denim|   S|        Germany|     Vietnam|Comfort|   95|          0|2022-07-19|       null|       105254|        200|2022|    7|          29|-0.2944616217868008| -0.9556633054034706|                1|                           1|                   1|                   1|         95|                         0|                2099-01-01|[0, 1, 2, 3, 4, 5...|               8|  2022-07-27|\n",
            "+-----+-----+--------+-----------+-------------+-------------+----+---------------+------------+-------+-----+-----------+----------+-----------+-------------+-----------+----+-----+------------+-------------------+--------------------+-----------------+----------------------------+--------------------+--------------------+-----------+--------------------------+--------------------------+--------------------+----------------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data has also become substantially larger (starting from about 130,000 rows). "
      ],
      "metadata": {
        "id": "IGFw7LZJVpVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IQCNkmGVoxW",
        "outputId": "d51aff8b-5b68-49bf-c4f3-1255442d3495"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2914060"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Statistical Features\n",
        "To calculate statistical features, such as the historical return rate of a product class, we again use window functions. However this time, we also use a date range because we cannot be sure if items will be returned or not if they have been ordered less than 30 days ago. "
      ],
      "metadata": {
        "id": "dFvAKsnEN-3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cal_hist_returns(df, suffix, keys, date_range, max_date):\n",
        "    \"\"\"\n",
        "    Use a rolling window to calculate the no. of purchase, no. of returns and return rate for (-inf, -return_window) dates\n",
        "    for the product group defined by keys.\n",
        "    \"\"\"\n",
        "    df_rr_daily = (df\n",
        "                   .groupBy(keys+['order_date'])\n",
        "                   .agg({\"is_returned\": \"sum\", \"item_trans_id\": \"count\"})\n",
        "                   .withColumn(\"n_days\", F.datediff(F.lit(max_date), F.col('order_date')))\n",
        "                  )\n",
        "\n",
        "    w = psw.partitionBy(keys).orderBy(F.desc('n_days')).rangeBetween(*date_range)\n",
        "\n",
        "    # Compute the rolling count of purchased and returned items for the last -return_window days\n",
        "    df_rr_daily = (df_rr_daily\n",
        "                   .withColumn(f'ret_{suffix}', F.sum('sum(is_returned)').over(w))\n",
        "                   .withColumn(f'pur_{suffix}', F.sum('count(item_trans_id)').over(w))\n",
        "                   .withColumn(f'rr_{suffix}', F.round(F.col(f'ret_{suffix}')/F.col(f'pur_{suffix}'), 3))\n",
        "                   .select(keys + ['order_date', f'rr_{suffix}'])\n",
        "                   .withColumnRenamed('order_date', 'current_date')\n",
        "                  )\n",
        "    \n",
        "    return df_rr_daily"
      ],
      "metadata": {
        "id": "Jpz0uhVPOHCY"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this example we will be calculating the historical return rate per country, per product group. The output is a dataframe with the return rate for every unique combination of country and product group. As can be seen, the historical return rates must be calculated on an *unexploded* dataframe."
      ],
      "metadata": {
        "id": "-2d9Jn5jPLSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define keys for category and product type\n",
        "keys_group = ['sold_to_country',  'product_group']\n",
        "\n",
        "return_window = 33\n",
        "\n",
        "date_range = (psw.unboundedPreceding, -return_window)\n",
        "\n",
        "# - rr_cat_cnt_recent: return rate per country per category per gender\n",
        "max_date = df.agg({\"order_date\": 'max'}).collect()[0]['max(order_date)']\n",
        "\n",
        "df_rr_cat = cal_hist_returns(df_order_unexpl,\n",
        "                             \"group\",\n",
        "                             keys_group,\n",
        "                             date_range,\n",
        "                             max_date)\n",
        "\n",
        "df_rr_cat.filter(df_rr_cat.rr_group.isNotNull()).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kk2GvAfeOwD3",
        "outputId": "4e42fe1a-7f76-435d-b49b-bbfc58e0b3f8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-------------+------------+--------+\n",
            "|sold_to_country|product_group|current_date|rr_group|\n",
            "+---------------+-------------+------------+--------+\n",
            "|        Austria|         Belt|  2021-09-04|     0.0|\n",
            "|        Austria|         Belt|  2021-09-05|     0.0|\n",
            "|        Austria|         Belt|  2021-09-07|   0.667|\n",
            "|        Austria|         Belt|  2021-09-08|   0.571|\n",
            "|        Austria|         Belt|  2021-09-09|     0.5|\n",
            "|        Austria|         Belt|  2021-09-10|   0.444|\n",
            "|        Austria|         Belt|  2021-09-11|   0.455|\n",
            "|        Austria|         Belt|  2021-09-12|   0.455|\n",
            "|        Austria|         Belt|  2021-09-13|     0.5|\n",
            "|        Austria|         Belt|  2021-09-14|   0.462|\n",
            "|        Austria|         Belt|  2021-09-18|   0.467|\n",
            "|        Austria|         Belt|  2021-09-19|   0.467|\n",
            "|        Austria|         Belt|  2021-09-20|   0.467|\n",
            "|        Austria|         Belt|  2021-09-21|   0.467|\n",
            "|        Austria|         Belt|  2021-09-22|     0.5|\n",
            "|        Austria|         Belt|  2021-09-24|   0.429|\n",
            "|        Austria|         Belt|  2021-09-25|   0.435|\n",
            "|        Austria|         Belt|  2021-09-27|   0.423|\n",
            "|        Austria|         Belt|  2021-09-29|   0.393|\n",
            "|        Austria|         Belt|  2021-09-30|   0.393|\n",
            "+---------------+-------------+------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can join the historical return rates to our original data, fill missing values and fix non-sensical values."
      ],
      "metadata": {
        "id": "kcIdks9VPeYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " df = df.join(df_rr_cat, on=keys_group + ['current_date'], how='left')\n",
        "\n",
        " df = df.na.fill({'rr_group': 0.4})\n",
        "\n",
        " df = df.withColumn('rr_group', F.when(F.col('rr_group') < 0.09, 0.4)\n",
        "                                 .otherwise(F.col('rr_group')))"
      ],
      "metadata": {
        "id": "9q4LzOqvPGyO"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Customer Features\n",
        "Now for the most exciting and often most useful part: customer features. The first step is to calculate the historical return rate per customer, for every date. For this purpose we can use the same approach as calculating statistical features per product group."
      ],
      "metadata": {
        "id": "GIL9MD6YP9Pu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keys_cust = ['customer_id']\n",
        "\n",
        "recent_date_range = (psw.unboundedPreceding, -return_window)\n",
        "\n",
        "keys_cust = ['customer_id']\n",
        "df_rr_cust = cal_hist_returns(df_order_unexpl,\n",
        "                              \"cust\",\n",
        "                              keys_cust,\n",
        "                              date_range,\n",
        "                              max_date)\n",
        "\n",
        "df = df.join(df_rr_cust, on=keys_cust + ['current_date'], how='left')"
      ],
      "metadata": {
        "id": "9IwMBY79QXRf"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also easily calculate each customer's account age by calculating the number of days since the first purchase."
      ],
      "metadata": {
        "id": "7W5zTZsAQwj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = psw.orderBy('order_date').partitionBy('customer_id')\n",
        "\n",
        "df = df.withColumn('cust_first_purchase_date', F.first('order_date').over(w))\n",
        "df = df.withColumn('cust_account_age',\n",
        "                           F.datediff(F.col('order_date'), F.col('cust_first_purchase_date')))"
      ],
      "metadata": {
        "id": "gPImybvdQp-4"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is also useful to create a dummy column to indicate if this is the customers first order."
      ],
      "metadata": {
        "id": "NsV9WYHBQ9gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn('is_first_order',\n",
        "                  (F.col('cust_first_purchase_date') == F.col('order_date')).cast('int'))"
      ],
      "metadata": {
        "id": "XppZEbjqREmG"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also use window functions to create purchase- and return counts for for each customer. Here we don't have to limit the end date of the window to thirty days before, because we would like to know if a return was made even yesterday."
      ],
      "metadata": {
        "id": "4XqU-49TRTen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_order_unexpl = df_order_unexpl.withColumn(\"n_days\", F.datediff(F.lit(max_date), F.col('order_date')))\n",
        "\n",
        "# Total number of returns made by the customer in past year\n",
        "w = psw.partitionBy([\"customer_id\"]).orderBy(F.desc('n_days')).rangeBetween(-366, -1)\n",
        "\n",
        "df_order_unexpl = (df_order_unexpl\n",
        "                   .withColumn('pur_cust_before', F.count(\"item_trans_id\").over(w))\n",
        "                   .withColumn('ret_cust_before', F.sum(\"is_returned\").over(w))\n",
        "                  )\n",
        "\n",
        "# Total number of returns made by the customer per product class in past year\n",
        "w = psw.partitionBy([\"customer_id\", \"product_class\"]).orderBy(F.desc('n_days')).rangeBetween(-366, -1)\n",
        "\n",
        "df_order_unexpl = (df_order_unexpl\n",
        "                   .withColumn('pur_same_pc_cust_before', F.count(\"item_trans_id\").over(w))\n",
        "                   .withColumn('ret_same_pc_cust_before', F.sum(\"is_returned\").over(w))\n",
        "                   )\n"
      ],
      "metadata": {
        "id": "hyss0tELRLCR"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we can join the customer features back to our original data."
      ],
      "metadata": {
        "id": "8k-Z9m-2SKsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.join(df_order_unexpl.select(\"customer_id\", \"order_date\", \"item_trans_id\",\n",
        "                                    'pur_cust_before',\n",
        "                                    'ret_cust_before',\n",
        "                                    'pur_same_pc_cust_before',\n",
        "                                    'ret_same_pc_cust_before'),\n",
        "                     \n",
        "                     on=[\"customer_id\", \"order_date\", \"item_trans_id\"], how=\"left\")\n"
      ],
      "metadata": {
        "id": "nj8BQaMVSTEx"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to the lazy execution, the commands above will only be executed once a command such as 'show' or 'count' is called."
      ],
      "metadata": {
        "id": "p6C_D9STX_Ip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2BL1nfnX7QQ",
        "outputId": "353f8bb7-27f8-47e2-d7a4-9e17c61ba7d8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+-------------+------------+---------------+-------------+-----+-----+--------+-------------+----+------------+----+-----+-----------+-----------+-----------+----+-----+------------+--------------------+-------------------+-----------------+----------------------------+--------------------+--------------------+-----------+--------------------------+--------------------------+--------------------+----------------+--------+-------+------------------------+----------------+--------------+---------------+---------------+-----------------------+-----------------------+\n",
            "|customer_id|order_date|item_trans_id|current_date|sold_to_country|product_group|color|brand|order_id|product_class|size|prod_country| fit|price|is_returned|return_date|day_of_year|year|month|week_of_year|      sin_order_date|     cos_order_date|n_item_same_order|n_prod_same_ptype_same_order|n_same_pc_same_order|n_same_pg_same_order|order_value|is_purchase_order_returned|purchase_order_return_date|arr_days_after_order|days_after_order|rr_group|rr_cust|cust_first_purchase_date|cust_account_age|is_first_order|pur_cust_before|ret_cust_before|pur_same_pc_cust_before|ret_same_pc_cust_before|\n",
            "+-----------+----------+-------------+------------+---------------+-------------+-----+-----+--------+-------------+----+------------+----+-----+-----------+-----------+-----------+----+-----+------------+--------------------+-------------------+-----------------+----------------------------+--------------------+--------------------+-----------+--------------------------+--------------------------+--------------------+----------------+--------+-------+------------------------+----------------+--------------+---------------+---------------+-----------------------+-----------------------+\n",
            "|          5|2022-07-04|        97069|  2022-07-04|          Italy|        Dress| Blue| Zara|   83648|    Non-denim|   S|    Portugal|Slim|  234|          0|       null|        185|2022|    7|          27|-0.04084439154329...|-0.9991655196610109|                2|                           2|                   2|                   1|        420|                         0|                2099-01-01|[0, 1, 2, 3, 4, 5...|               0|   0.488|   null|              2022-07-04|               0|             1|              0|           null|                      0|                   null|\n",
            "|          5|2022-07-04|        97069|  2022-07-05|          Italy|        Dress| Blue| Zara|   83648|    Non-denim|   S|    Portugal|Slim|  234|          0|       null|        185|2022|    7|          27|-0.04084439154329...|-0.9991655196610109|                2|                           2|                   2|                   1|        420|                         0|                2099-01-01|[0, 1, 2, 3, 4, 5...|               1|   0.487|   null|              2022-07-04|               0|             1|              0|           null|                      0|                   null|\n",
            "|          5|2022-07-04|        97069|  2022-07-06|          Italy|        Dress| Blue| Zara|   83648|    Non-denim|   S|    Portugal|Slim|  234|          0|       null|        185|2022|    7|          27|-0.04084439154329...|-0.9991655196610109|                2|                           2|                   2|                   1|        420|                         0|                2099-01-01|[0, 1, 2, 3, 4, 5...|               2|   0.489|   null|              2022-07-04|               0|             1|              0|           null|                      0|                   null|\n",
            "|          5|2022-07-04|        97069|  2022-07-07|          Italy|        Dress| Blue| Zara|   83648|    Non-denim|   S|    Portugal|Slim|  234|          0|       null|        185|2022|    7|          27|-0.04084439154329...|-0.9991655196610109|                2|                           2|                   2|                   1|        420|                         0|                2099-01-01|[0, 1, 2, 3, 4, 5...|               3|    0.49|   null|              2022-07-04|               0|             1|              0|           null|                      0|                   null|\n",
            "|          5|2022-07-04|        97069|  2022-07-08|          Italy|        Dress| Blue| Zara|   83648|    Non-denim|   S|    Portugal|Slim|  234|          0|       null|        185|2022|    7|          27|-0.04084439154329...|-0.9991655196610109|                2|                           2|                   2|                   1|        420|                         0|                2099-01-01|[0, 1, 2, 3, 4, 5...|               4|   0.489|   null|              2022-07-04|               0|             1|              0|           null|                      0|                   null|\n",
            "|          5|2022-07-04|        97069|  2022-07-09|          Italy|        Dress| Blue| Zara|   83648|    Non-denim|   S|    Portugal|Slim|  234|          0|       null|        185|2022|    7|          27|-0.04084439154329...|-0.9991655196610109|                2|                           2|                   2|                   1|        420|                         0|                2099-01-01|[0, 1, 2, 3, 4, 5...|               5|   0.486|   null|              2022-07-04|               0|             1|              0|           null|                      0|                   null|\n",
            "|          5|2022-07-04|        97069|  2022-07-10|          Italy|        Dress| Blue| Zara|   83648|    Non-denim|   S|    Portugal|Slim|  234|          0|       null|        185|2022|    7|          27|-0.04084439154329...|-0.9991655196610109|                2|                           2|                   2|                   1|        420|                         0|                2099-01-01|[0, 1, 2, 3, 4, 5...|               6|   0.486|   null|              2022-07-04|               0|             1|              0|           null|                      0|                   null|\n",
            "|          5|2022-07-04|        97069|  2022-07-11|          Italy|        Dress| Blue| Zara|   83648|    Non-denim|   S|    Portugal|Slim|  234|          0|       null|        185|2022|    7|          27|-0.04084439154329...|-0.9991655196610109|                2|                           2|                   2|                   1|        420|                         0|                2099-01-01|[0, 1, 2, 3, 4, 5...|               7|   0.487|   null|              2022-07-04|               0|             1|              0|           null|                      0|                   null|\n",
            "|          5|2022-07-04|        97069|  2022-07-12|          Italy|        Dress| Blue| Zara|   83648|    Non-denim|   S|    Portugal|Slim|  234|          0|       null|        185|2022|    7|          27|-0.04084439154329...|-0.9991655196610109|                2|                           2|                   2|                   1|        420|                         0|                2099-01-01|[0, 1, 2, 3, 4, 5...|               8|   0.485|   null|              2022-07-04|               0|             1|              0|           null|                      0|                   null|\n",
            "|          5|2022-07-04|        97069|  2022-07-13|          Italy|        Dress| Blue| Zara|   83648|    Non-denim|   S|    Portugal|Slim|  234|          0|       null|        185|2022|    7|          27|-0.04084439154329...|-0.9991655196610109|                2|                           2|                   2|                   1|        420|                         0|                2099-01-01|[0, 1, 2, 3, 4, 5...|               9|   0.486|   null|              2022-07-04|               0|             1|              0|           null|                      0|                   null|\n",
            "|          5|2022-07-04|        97069|  2022-07-14|          Italy|        Dress| Blue| Zara|   83648|    Non-denim|   S|    Portugal|Slim|  234|          0|       null|        185|2022|    7|          27|-0.04084439154329...|-0.9991655196610109|                2|                           2|                   2|                   1|        420|                         0|                2099-01-01|[0, 1, 2, 3, 4, 5...|              10|   0.485|   null|              2022-07-04|               0|             1|              0|           null|                      0|                   null|\n",
            "|          5|2022-07-04|        97069|  2022-07-15|          Italy|        Dress| Blue| Zara|   83648|    Non-denim|   S|    Portugal|Slim|  234|          0|       null|        185|2022|    7|          27|-0.04084439154329...|-0.9991655196610109|                2|                           2|                   2|                   1|        420|                         0|                2099-01-01|[0, 1, 2, 3, 4, 5...|              11|   0.483|   null|              2022-07-04|               0|             1|              0|           null|                      0|                   null|\n",
            "|          5|2022-07-04|        97069|  2022-07-16|          Italy|        Dress| Blue| Zara|   83648|    Non-denim|   S|    Portugal|Slim|  234|          0|       null|        185|2022|    7|          27|-0.04084439154329...|-0.9991655196610109|                2|                           2|                   2|                   1|        420|                         0|                2099-01-01|[0, 1, 2, 3, 4, 5...|              12|   0.484|   null|              2022-07-04|               0|             1|              0|           null|                      0|                   null|\n",
            "|          5|2022-07-04|        97069|  2022-07-17|          Italy|        Dress| Blue| Zara|   83648|    Non-denim|   S|    Portugal|Slim|  234|          0|       null|        185|2022|    7|          27|-0.04084439154329...|-0.9991655196610109|                2|                           2|                   2|                   1|        420|                         0|                2099-01-01|[0, 1, 2, 3, 4, 5...|              13|   0.485|   null|              2022-07-04|               0|             1|              0|           null|                      0|                   null|\n",
            "|          5|2022-07-04|        97069|  2022-07-18|          Italy|        Dress| Blue| Zara|   83648|    Non-denim|   S|    Portugal|Slim|  234|          0|       null|        185|2022|    7|          27|-0.04084439154329...|-0.9991655196610109|                2|                           2|                   2|                   1|        420|                         0|                2099-01-01|[0, 1, 2, 3, 4, 5...|              14|   0.485|   null|              2022-07-04|               0|             1|              0|           null|                      0|                   null|\n",
            "|          5|2022-07-04|        97069|  2022-07-19|          Italy|        Dress| Blue| Zara|   83648|    Non-denim|   S|    Portugal|Slim|  234|          0|       null|        185|2022|    7|          27|-0.04084439154329...|-0.9991655196610109|                2|                           2|                   2|                   1|        420|                         0|                2099-01-01|[0, 1, 2, 3, 4, 5...|              15|   0.484|   null|              2022-07-04|               0|             1|              0|           null|                      0|                   null|\n",
            "|          5|2022-07-04|        97069|  2022-07-20|          Italy|        Dress| Blue| Zara|   83648|    Non-denim|   S|    Portugal|Slim|  234|          0|       null|        185|2022|    7|          27|-0.04084439154329...|-0.9991655196610109|                2|                           2|                   2|                   1|        420|                         0|                2099-01-01|[0, 1, 2, 3, 4, 5...|              16|   0.483|   null|              2022-07-04|               0|             1|              0|           null|                      0|                   null|\n",
            "|          5|2022-07-04|        97069|  2022-07-21|          Italy|        Dress| Blue| Zara|   83648|    Non-denim|   S|    Portugal|Slim|  234|          0|       null|        185|2022|    7|          27|-0.04084439154329...|-0.9991655196610109|                2|                           2|                   2|                   1|        420|                         0|                2099-01-01|[0, 1, 2, 3, 4, 5...|              17|   0.484|   null|              2022-07-04|               0|             1|              0|           null|                      0|                   null|\n",
            "|          5|2022-07-04|        97069|  2022-07-22|          Italy|        Dress| Blue| Zara|   83648|    Non-denim|   S|    Portugal|Slim|  234|          0|       null|        185|2022|    7|          27|-0.04084439154329...|-0.9991655196610109|                2|                           2|                   2|                   1|        420|                         0|                2099-01-01|[0, 1, 2, 3, 4, 5...|              18|   0.485|   null|              2022-07-04|               0|             1|              0|           null|                      0|                   null|\n",
            "|          5|2022-07-04|        97069|  2022-07-23|          Italy|        Dress| Blue| Zara|   83648|    Non-denim|   S|    Portugal|Slim|  234|          0|       null|        185|2022|    7|          27|-0.04084439154329...|-0.9991655196610109|                2|                           2|                   2|                   1|        420|                         0|                2099-01-01|[0, 1, 2, 3, 4, 5...|              19|   0.484|   null|              2022-07-04|               0|             1|              0|           null|                      0|                   null|\n",
            "+-----------+----------+-------------+------------+---------------+-------------+-----+-----+--------+-------------+----+------------+----+-----+-----------+-----------+-----------+----+-----+------------+--------------------+-------------------+-----------------+----------------------------+--------------------+--------------------+-----------+--------------------------+--------------------------+--------------------+----------------+--------+-------+------------------------+----------------+--------------+---------------+---------------+-----------------------+-----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Besides backward looking features, we can also create forward customer features. It only makes sense to do this until the return window closes. "
      ],
      "metadata": {
        "id": "jts_cs2rY4bF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn(\"n_days\", F.datediff(F.lit(max_date), F.col('order_date')))\n",
        "\n",
        "w = psw.partitionBy([\"customer_id\", \"current_date\"]).orderBy(F.desc('n_days')).rangeBetween(1, return_window)\n",
        "\n",
        "df_all = (df\n",
        "          .withColumn('pur_same_cust_after', F.count(\"item_trans_id\").over(w))\n",
        "          .withColumn('ret_same_cust_after', F.sum(\"is_returned\").over(w))\n",
        "          )"
      ],
      "metadata": {
        "id": "qraZs8COYimi"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For many orders values will be missing for this feature, which has to be imputed."
      ],
      "metadata": {
        "id": "54KkQBQMZmhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cust_feat = ['pur_cust_before',\n",
        "             'ret_cust_before',\n",
        "             'pur_same_pc_cust_before',\n",
        "             'ret_same_pc_cust_before',\n",
        "             'pur_same_cust_after',\n",
        "             'ret_same_cust_after']\n",
        "\n",
        "df_all = df_all.fillna(0, cust_feat)          "
      ],
      "metadata": {
        "id": "f1THuYUhZUP4"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One final step is to selectively deal with missing values per feature."
      ],
      "metadata": {
        "id": "TZMlpJ2Na-63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill selectively per column\n",
        "df_all = df_all.na.fill({'prod_country': 'unknown',\n",
        "                         'fit': 'no_fit',\n",
        "                         'customer_id': 0,\n",
        "                         'size': 'no_size',\n",
        "                         'color': 'unknown'\n",
        "                        })"
      ],
      "metadata": {
        "id": "wXPJ05QMaww6"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That concludes the feature engineering! Now on to modeling."
      ],
      "metadata": {
        "id": "c2yP11tQajlm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZkU2zuuwjFhq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modeling"
      ],
      "metadata": {
        "id": "3zlB-Ss4baJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline, PipelineModel\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, RegressionEvaluator\n",
        "from synapse.ml.lightgbm import LightGBMClassifier, LightGBMClassificationModel\n",
        "from pyspark.ml.functions import vector_to_array\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "SIYwyYHXfQec"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Building a Pipeline\n",
        "We must first indicate which transformations should be applied to which features. Categorical features containing string should first be integer encoded and one-hot encoded after."
      ],
      "metadata": {
        "id": "04PhD0bVfuSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Columns that need integer encoding\n",
        "str_cols = ['color', 'brand', 'sold_to_country', 'prod_country', 'product_class', \n",
        "            'product_group', 'size', 'fit']\n",
        "\n",
        "outstr_cols = [col+'_ind' for col in str_cols]\n",
        "\n",
        "# Columns that need one-hot encoding\n",
        "ohe_cols = outstr_cols + ['month', 'week_of_year']\n",
        "\n",
        "outohe_cols = [col+'_dummy' for col in ohe_cols]\n",
        "\n",
        "# Adding numerical features\n",
        "predictor_cols = outohe_cols + ['sin_order_date', 'cos_order_date', 'price',\n",
        "                                'order_value', 'n_item_same_order', \n",
        "                                'n_same_pc_same_order', 'n_same_pg_same_order', \n",
        "                                'rr_group', 'rr_cust'\n",
        "                                'pur_cust_before', 'ret_cust_before',\n",
        "                                'pur_same_pc_cust_before', 'ret_same_pc_cust_before',\n",
        "                                'cust_account_age', 'first_order',\n",
        "                                'pur_same_cust_after', 'ret_same_cust_after']  \n",
        "\n",
        "print(predictor_cols)\n",
        "print(len(predictor_cols))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cae9TcgDfaKH",
        "outputId": "45e00fc3-c83b-44b7-da1d-6d7aee2ec7c3"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['color_ind_dummy', 'brand_ind_dummy', 'sold_to_country_ind_dummy', 'prod_country_ind_dummy', 'product_class_ind_dummy', 'product_group_ind_dummy', 'size_ind_dummy', 'fit_ind_dummy', 'month_dummy', 'week_of_year_dummy', 'sin_order_date', 'cos_order_date', 'price', 'order_value', 'n_item_same_order', 'n_same_pc_same_order', 'n_same_pg_same_order', 'rr_group', 'rr_custpur_cust_before', 'ret_cust_before', 'pur_same_pc_cust_before', 'ret_same_pc_cust_before', 'cust_account_age', 'first_order', 'pur_same_cust_after', 'ret_same_cust_after']\n",
            "26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we must instantiate the right transformer classes as well as the estimator and combine these into a pipeline."
      ],
      "metadata": {
        "id": "vmWeUYGfhirm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create indexer object\n",
        "indexer = StringIndexer(inputCols = str_cols, outputCols = outstr_cols, handleInvalid = 'keep')\n",
        "\n",
        "# Create onehotencoder object \n",
        "ohe_encoder = OneHotEncoder(inputCols = ohe_cols, outputCols = outohe_cols, handleInvalid = 'keep')\n",
        "\n",
        "# Create vector assembler object\n",
        "assembler = VectorAssembler(inputCols = predictor_cols, outputCol ='features', handleInvalid = 'keep')\n",
        "\n",
        "# Create a LightGBMClassifier object\n",
        "lgbm = LightGBMClassifier(labelCol = 'is_returned')\n",
        "\n",
        "# Create Pipeline\n",
        "pipeline = Pipeline(stages = [indexer, ohe_encoder, assembler, lgbm]) "
      ],
      "metadata": {
        "id": "cZ3iE7Qshi1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also require an evaluator class to check for model performane."
      ],
      "metadata": {
        "id": "nSWrmUpqiesr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an evaluator object\n",
        "evaluator = BinaryClassificationEvaluator(labelCol = 'is_returned')"
      ],
      "metadata": {
        "id": "Ig1GFaluilvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Splitting the Data\n",
        "The next step is to split our training and testing data for a backtest according to some business rules. Specifically it must be taken into account that the thirty days before the model training date cannot be used due to size of the return window."
      ],
      "metadata": {
        "id": "4R-8fKQvi_il"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_split(df, start_date = '2022-08-15', num_days = 30, test_gap = 33, train_length=365):\n",
        "    \n",
        "    \"\"\" \n",
        "    Generates a training and test according to business rules.\n",
        "\n",
        "    Input:\n",
        "    - data\n",
        "    - first day of test set\n",
        "    - number of days in the test set\n",
        "    - gap to keep between last day of training data and first day of testing\n",
        "    - number of historical order dates to train on\n",
        "\n",
        "    Output:\n",
        "    - training data\n",
        "    - testing data\n",
        "    \"\"\"\n",
        "    \n",
        "    testset_start_date = F.to_date(F.lit(start_date))\n",
        "    testset_end_date = F.date_add(F.lit(testset_start_date), num_days)\n",
        "    \n",
        "    model_train_date = F.date_sub(F.lit(testset_start_date), 1)\n",
        "\n",
        "    trainset_end_date = F.date_sub(F.lit(testset_start_date), test_gap)\n",
        "    \n",
        "\n",
        "    df_copy = df.alias('df_copy')\n",
        "\n",
        "    df_train =  df_copy.filter(((df_copy.order_date >= F.date_sub(F.lit(trainset_end_date), train_length)) & \n",
        "                                (df_copy.order_date <= trainset_end_date))  \n",
        "                                  )\n",
        "\n",
        "    # If the test gap is shorter than the return window, the labels must be adjusted\n",
        "    # in case a return was not known yet on the model training date\n",
        "    df_train = df_train.withColumn('is_returned', F.when(df_train.return_date > model_train_date, 0)\n",
        "                                                   .otherwise(df_train.is_returned))\n",
        "    \n",
        "    df_test = df_copy.filter((df_copy.current_date >= testset_start_date)\\\n",
        "                           & (df_copy.current_date <= testset_end_date))\n",
        "    \n",
        "    \n",
        "    return df_train, df_test"
      ],
      "metadata": {
        "id": "671MWDPdi_H0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation Function\n",
        "Another function is required to make NMV predictions, aggregate by order date and calculate absolute percent error. Predictions are then aggregated to the prediction date level to calculate the mean absolute percent error for every prediction date."
      ],
      "metadata": {
        "id": "j-OaPyLol9Op"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vec_to_arr(df, new_col = \"prob\", old_col = \"probability\"):\n",
        "  \"\"\" Helper function for evaluate_model\"\"\" \n",
        "    df = df.withColumn(new_col, vector_to_array(old_col))\n",
        "    return df"
      ],
      "metadata": {
        "id": "V6KZ-eg3o8vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, data, country=False):\n",
        "                   \n",
        "    \"\"\" Calculates total sales, actual nmv (net merchandise value) and predicted nmv for a date or list of dates.\n",
        "        Subsequently calculates the absolute percentage error for the nmv value prediction for each date.\n",
        "        Finally calculates the mean absolute percentage error and the mean bias for all the dates predicted on for each current date.\n",
        "        \n",
        "        Input: \n",
        "            - a binary classification model\n",
        "            - an exploded test dataset with a current_date and price columns\n",
        "            - display results on country level or not\n",
        "\n",
        "        Output:\n",
        "            - dataframe detailing total sales, actual nmv, predicted nmv, absolute percent error\n",
        "            - MAPE (mean absolute percent error)\n",
        "            - bias\n",
        "            \n",
        "            Output is returned as a tuple.\"\"\"\n",
        "    \n",
        "    # Make predictions with model\n",
        "    df_pred = model.transform(data)\n",
        "    df_pred = vec_to_arr(df_pred)\n",
        "    \n",
        "    # Calculate item-level predicted- and actual NMV\n",
        "    df_pred = df_pred.withColumn('nmv_pred', (1 - df_pred['prob'][1]) * df_pred['item_value_eur'])\n",
        "    df_pred = df_pred.withColumn('nmv_act', F.col(\"item_value_eur\") * (1 - F.col(\"is_returned\")))\n",
        "    \n",
        "    \n",
        "    if country == False:\n",
        "            df_res = (df_pred.groupBy([\"order_date\", \"current_date\"])\n",
        "                    .agg(F.round(F.sum(\"price\")).alias('sales_value'),\n",
        "                         F.round(F.sum(\"nmv_act\")).alias('nmv_act'),\n",
        "                         F.round(F.sum(\"nmv_pred\")).alias('nmv_pred')\n",
        "                        ))\n",
        "            \n",
        "    if country == True:\n",
        "            df_res = (df_pred.groupBy([\"order_date\", \"current_date\", \"sold_to_country\"])\n",
        "                    .agg(F.round(F.sum(\"price\")).alias('sales_value'),\n",
        "                         F.round(F.sum(\"nmv_act\")).alias('nmv_act'),\n",
        "                         F.round(F.sum(\"nmv_pred\")).alias('nmv_pred')\n",
        "                        ))\n",
        "    \n",
        "    df_res = df_res.withColumn('APE', F.round(F.abs(df_res.nmv_act - df_res.nmv_pred) / df_res.nmv_act *100, 1))\n",
        "   \n",
        "    if country == False:\n",
        "            df_per_current_date = (df_res.groupBy('current_date')\n",
        "                              .agg(F.round(F.mean(\"APE\"), 3).alias('MAPE'),\n",
        "                                  F.round(F.sum(\"nmv_act\")).alias('sum_nmv_act'),\n",
        "                                  F.round(F.sum(\"nmv_pred\")).alias('sum_nmv_pred'),\n",
        "                                  )) \n",
        "    if country == True:\n",
        "            df_per_current_date = (df_res.groupBy(['current_date', 'sold_to_country'])\n",
        "                              .agg(F.round(F.mean(\"APE\"), 3).alias('MAPE'),\n",
        "                                  F.round(F.sum(\"nmv_act\")).alias('sum_nmv_act'),\n",
        "                                  F.round(F.sum(\"nmv_pred\")).alias('sum_nmv_pred'),\n",
        "                                  )) \n",
        "                                \n",
        "    mape = df_per_current_date.agg({'MAPE':'mean'})\n",
        "    mean_bias = df_per_current_date.agg({'bias':'mean'})\n",
        "    \n",
        "    return df_pred, df_res, df_per_current_date.sort('current_date'), mape"
      ],
      "metadata": {
        "id": "dRm4KJVCl81_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training the model\n",
        "From here on, training and evaluating the model is straightforward. We simply split the data according to our previously defined function and proceed to training."
      ],
      "metadata": {
        "id": "KXXBQ-SOnHzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = generate_split()"
      ],
      "metadata": {
        "id": "A_-3mJw8nH75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = pipeline.fit(df_train)"
      ],
      "metadata": {
        "id": "rWZMCIS1p3K0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred, df_res, df_current_date, mape = evaluate_model(model, df_test)"
      ],
      "metadata": {
        "id": "knjiwyNGptTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Checking Performance\n",
        "Now we can analyze the results that we have obtained."
      ],
      "metadata": {
        "id": "l1Dx_gnnqLDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_res.show()"
      ],
      "metadata": {
        "id": "b81AL10SqSGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_current_date.show(31)"
      ],
      "metadata": {
        "id": "KBoK1t99qThQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a final step it is also possible to check the importance of each feature. The spark LightGBM module offers two methods for this: split and gain. \n",
        "\n",
        "*   split: the number of nodes that were split on this feature\n",
        "*   gain: total information gain for all splits over this feature\n",
        "\n"
      ],
      "metadata": {
        "id": "dQi7av2gq07s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "va = model.stages[-2]\n",
        "lgbm = model.stages[-1]\n",
        "\n",
        "importances = dict(zip(va.getInputCols(), lgbm.getFeatureImportances(importance_type = 'gain')))\n",
        "\n",
        "importances = pd.DataFrame.from_dict(importances, orient='index', columns = ['importance'])\n",
        "importances = importances.sort_values('importance', ascending = False)\n",
        "\n",
        "importances.plot.barh()"
      ],
      "metadata": {
        "id": "R3A0i25bqlin"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}